\documentclass[a4paper,10pt,ngerman]{scrartcl}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[a4paper,margin=2.5cm,footskip=0.5cm]{geometry}

% Die nächsten drei Felder bitte anpassen:
\newcommand{\Aufgabe}{Aufgabe 1: \LaTeX-Dokument} % Aufgabennummer und Aufgabennamen angeben
\newcommand{\TeilnahmeId}{?????}                  % Teilnahme-ID angeben
\newcommand{\Name}{Vor- und Nachname}             % Name des Bearbeiter / der Bearbeiterin dieser Aufgabe angeben


% Kopf- und Fußzeilen
\usepackage{scrlayer-scrpage, lastpage}
\setkomafont{pageheadfoot}{\large\textrm}
\lohead{\Aufgabe}
\rohead{Teilnahme-ID: \TeilnahmeId}
\cfoot*{\thepage{}/\pageref{LastPage}}

% Position des Titels
\usepackage{titling}
\setlength{\droptitle}{-1.0cm}

% Für mathematische Befehle und Symbole
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Für Bilder
\usepackage{graphicx}

% Für Algorithmen
\usepackage{algpseudocode}

% Für Quelltext
\usepackage{listings}
\usepackage{color}

\usepackage{forest}
\usepackage{float}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
    keywordstyle=\color{blue},commentstyle=\color{mygreen},
    stringstyle=\color{mymauve},rulecolor=\color{black},
    basicstyle=\footnotesize\ttfamily,numberstyle=\tiny\color{mygray},
    captionpos=b, % sets the caption-position to bottom
    keepspaces=true, % keeps spaces in text
    numbers=left, numbersep=5pt, showspaces=false,showstringspaces=true,
    showtabs=false, stepnumber=2, tabsize=2, title=\lstname
}

\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{satz}{Satz}
\newtheorem{beispiel}{Beispiel}

% Diese beiden Pakete müssen zuletzt geladen werden
%\usepackage{hyperref} % Anklickbare Links im Dokument
\usepackage{cleveref}

% Daten für die Titelseite
\title{\textbf{\Huge\Aufgabe}}
\author{\LARGE Teilnahme-ID: \LARGE \TeilnahmeId \\\\
\LARGE Bearbeiter/-in dieser Aufgabe: \\
\LARGE \Name\\\\}
\date{\LARGE\today}

\begin{document}

    \maketitle
    \tableofcontents

    \vspace{0.5cm}

    \textbf{Anleitung:} Trage oben in den Zeilen 8 bis 10 die Aufgabennummer, die Teilnahme-ID und die/den Bearbeiterin/Bearbeiter dieser Aufgabe mit Vor- und Nachnamen ein.
    Vergiss nicht, auch den Aufgabennamen anzupassen (statt "`\LaTeX-Dokument"')!

    Dann kannst du dieses Dokument mit deiner \LaTeX-Umgebung übersetzen.
    Die Texte, die hier bereits stehen, geben ein paar Hinweise zur
    Einsendung. Du solltest sie aber in deiner Einsendung wieder entfernen!


    \section{Lösungsidee}
    TODO vlt kurzfassung/zusammenfassung

    \subsection{Huffman Codierung}
    TODO Quelle vlt: https://people.eng.unimelb.edu.au/ammoffat/abstracts/compsurv19moffat.pdf\\
    David Huffman hat 1952 eine Methode veröffentlicht, die heute als \textit{Huffman Codierung} bekannt ist.
    Er stellte eine Methode vor, um eine optimale Präfixfreie Codierung für einen bestimmten Text zu finden.
    Dabei geht man von einem Alphabet $A$ mit $n$ verschiedenen Zeichen $a_1, \dots, a_n \in A$ aus, gemeinsam mit der Häufigkeitsverteilung der Zeichen $p_i = \frac {\text{Häufigkeit von $a_i$ im zu codierenden Text}} {\text{Länge des Textes}}$. Man nennt diese Antreffwahrscheinlichkeit $p_i$ eines Zeichens auch \textit{Frequenz} oder \textit{Gewichtung}.
    Wir nehmen an, dass das Alphabet nach absteigender Häufigkeit sortiert ist ist, also $p_i \ge p_{i + 1}$ für alle $0 \le i < n - 1$.
    Der Text soll mit einem Ausgabealphabet $O$ codiert werden, das aus $r$ verschiedenen Zeichen $o_1, \dots, o_r \in O$ besteht. In der Bwinf-Aufgabenstellung besteht dieses Ausgabealphabet $O$ aus den $r$ verschiedenen Perlen (die aber alle den gleichen Durchmesser haben). Um den ursprünglichen Text zu codieren, müssen wir nun jedem Buchstaben $a_i$ ein \textit{Codewort} $w_i$ zuordnen, dass aus einer Kette an Buchstaben aus dem Ausgabealphabet besteht $w_i = o_j o_k o_l \dots$. \\
    Diese Codierung soll \textit{Präfixfrei} sein, also kein Codewort soll Teil eines anderen Codeworts sein.
    Dadurch kann der Text als Aneinanderreihung von Codewörtern (ohne \glqq Komma\grqq~dazwischen) übertragen und eindeutig decodiert werden. \\
    Aufgrund von dieser Eigenschaft können wir den Code als einen Baum darstellen, der $n$ Blätter hat und bei dem jeder Knoten höchstens $r$ Kinder hat.
    \begin{definition}
        Wir nennen einen solchen Baum mit $n$ blättern und höchstens $r$ Kindern \textbf{valide}, da er eine mögliche Codetabelle darstellt.
    \end{definition}
    Jedes Blatt eines solchen Baums repräsentiert ein Codewort $w$, dass eindeutig durch den Pfad von der Wurzel des Baums zu diesem Blatt definiert ist. Der Pfad wird durch die Kanten des Baums definiert, die mit den Perlen beschriftet sind. Da alle Perlen gleich groß sind, also die Länge aller Buchstaben des Ausgabealphabets gleich ist, ist die Beschriftung der Kanten beliebig. Es ist lediglich wichtig, dass alle Kanten eines Knotens mit unterschiedlichen Buchstaben beschriftet sind. Die Länge des Codeworts $|w|$ entspricht der Anzahl der Kanten auf dem Pfad von der Wurzel zu diesem Blatt. \\
    Da wir eine optimale Codetabelle (also eine möglichst kurze Perlenkette) erstellen wollen, müssen wir die \glqq Kosten\grqq~eines Baums definieren.
    Diese Kosten eines Baums hängen natürlich auch davon ab, welches Codewort welchem Buchstaben zugeordnet wird. Für diese Definition gehen wir
    davon aus, dass wir eine solche Zuordnung $w_i \to a_i$ haben.
    \begin{definition}
        Die Kosten eines Baums $T$ ist definiert als das Produkt der Länge jedes Codeworts $w_i$ mit der Frequenz $p_i$ des codierten Buchstabens $a_i$: \[cost(T) = \sum^{i=0}_{i\le n} |w_i| \cdot p_i\]
    \end{definition}
    Da die Kosten eines Baumes proportional zu der Länge der resultierenden Perlenkette sind, kann die Aufgabenstellung darauf reduziert werden, den validen Baum $T$ mit den minimalen Kosten zu finden. \\
    Dafür ist aber auch die Zuordnung, welcher Buchstabe von welchem Codewort codiert werden soll, entscheidend.
    Für diese Aufgabenstellung ist die Zuordnung aber für jeden Baum eindeutig, da wir die Kosten des Baums minimieren wollen.
    Um das zu erreichen, müssen wir das längste Codewort zu dem Buchstaben zugeordnet, der am seltensten vorkommt und das kürzeste Codewort zu dem Buchstaben zuordnen, der am häufigsten vorkommt.
    Dafür ordnen wir im Folgenden die Blätter Baumes in aufsteigender Reihenfolge, also $|w_0| \le \dots \le |w_n|$.
    Da das Alphabet nach absteigender Reihenfolge sortiert ist, also $p_0 \ge \dots \ge p_n$, liefert die Zuordnung von $w_i$ zu $a_i$ für jeden Baum die geringsten Kosten. \\
    \begin{definition}
        Wir nennen einen solchen Baum, der die minimalen Kosten (kürzeste Perlenkette) für eine bestimmte Häufigkeitsverteilung hat \textbf{optimal}
    \end{definition}

    \subsubsection{Konstruktion des optimalen Baums}
    \begin{definition}
        Wir nennen einen $r$-när Baum, bei dem jeder Knoten maximal $r$ Kinder hat \textbf{vollständig}, wenn jeder Knoten genau $r$ Kinder hat.
    \end{definition}
    \begin{lemma}
        Ein optimaler binärer Huffman Baum ist vollständig. TODO braucht man das??
    \end{lemma}
    \begin{proof}
        Ein optimaler binärer Huffman Baum ist im allgemeinen vollständig, da in einem Optimalen Baum kein Knoten mit nur einem Kind existieren kann.
        Würde man diesen Knoten zu einem Blatt machen hätte man einen Baum mit der gleichen 3Anzahl an Blättern aber geringeren Kosten.
    \end{proof}
    Das gilt im allgemeinen Fall bei Bäumen mit $r > 2$ Kindern aber nicht. \\
    Für die allgemein bekannte Konstruktion (TODO Quelle) eines binären Huffman Baums werden wiederholt zwei Teilbäume zu einem zusammengefasst, bis schließlich nur noch einer übrig ist. % TODO vlt kurz beschreiben was passiert
    Im allgemeinen Fall müssen immer $r$ Teilbäume zu einem zusammengefasst werden, was aber nicht für jede Anzahl an Buchstaben $n$ im Alphabet immer funktioniert.
    \begin{beispiel}
        Für $n = 4$ werden im ersten Schritt drei Knoten zu einem zusammengefasst. Im nächsten sind nur noch zwei Knoten übrig. Würde man diese Knoten nun zu einem fertigen Baum kombinieren wäre dieser für bestimmte Häufigkeitsverteilungen (z.B. $p_0 = p_1 = p_2 = p_3$) nicht optimal.
            % TODO Bild
    \end{beispiel}
    Daher muss das Alphabet zuerst mit so vielen Platzhalterbuchstaben, deren Antreffwahrscheinlichkeit 0 ist, aufgefüllt werden, dass gilt: $n \mod (n - 1) = 1$.\\ % (TODO erklären warum genau des oder Quelle)
    Jetzt können wir mit der Konstruktion beginnen:
    \begin{enumerate}
        \item Erstelle für jeden Buchstaben $o_i$ im Alphabet (inklusive Platzhalter) einen Teilbaum (der aus einem Wurzelknoten besteht) und beschriften diesen mit der Frequenz $p_i$ des Buchstabens $o_i$.
        \item Wähle die $r$ Teilbäume mit den kleinsten Antreffwahrscheinlichkeiten. (Diese Wahl ist nicht eindeutig)
        \item Beschrifte einen neuen Knoten mit der Summe der Antreffwahrscheinlichkeiten der $r$ gewählten Teilbäume und erstelle einen neuen Teilbeum mit dem neuen Knoten als Wurzel und den gewählten Teilbäumen als Kinder.
        \item Wieder hole Schritt 2 und 3, bis nur noch ein Baum übrig ist.
    \end{enumerate}
    % TODO Wie kommt man dann an die codes
    TODO Bilder

    TODO QUelle für allgemeine Konstruktion

    \subsubsection{Beweis der optimalität}
    Der Standartbeweis für die Optimalität von Binären Huffman Bäumen kann leicht verallgemeinert werden, daher
    Dazu müssen wir zuerst das \glqq Sibling-Lemma\grqq~auf $r-$när Bäume verallgemeinern: % TODO Sibling lemma
    \begin{lemma}
        Seien $l_0, l_1, \dots l_{r - 1}$ die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit. Sie sind in einem Huffman Baum \glqq Geschwister\grqq, also Kinder des gleichen Knotens $Y$ und liegen auf der untersten Ebene des Baums.
    \end{lemma}
    \begin{proof}
        Die Buchstaben $l_0, l_1, \dots l_{r - 1}$ sind sicher Geschwister, da sie als erstes ausgewählt werden. \\
        Wenn $l_0, l_1, \dots l_{r - 1}$ nicht auf der unteresten Ebene des Baums liegen würden, dann müsste es einen Internen Knoten $X$ geben, dessen Antreffwahrscheinlichkeit kleiner ist als die des Knotens $Y$, dessen Kinder $l_0, l_1, \dots l_{r - 1}$ sind. Dafür müsste aber mindestens einer der Kinder von $X$ eine geringere Antreffwahrscheinlichkeit haben als einer der Kinder  $l_0, l_1, \dots l_{r - 1}$ von $Y$. Das wiederspricht aber unserer Anfänglichen Annahme, das $l_0, l_1, \dots l_{r - 1}$ die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit sind. Daher können wir sagen, dass $l_0, l_1, \dots l_{r - 1}$ immer auf der untersten Ebene des Baums liegen.
            % TODO so ein Bild wie hier: https://opendsa-server.cs.vt.edu/ODSA/Books/CS3/html/HuffProof.html
    \end{proof}
    % TODO irgendwo sagen, was r-när meint
    Damit können wir nun mithilfe von Induktion über die Größe $n$ des Alphabets den Beweis durchführen:
    \begin{satz}
        Die oben beschrieben Konstruktion für $r-$näre Huffman Bäume liefert einen optimalen Baum und damit eine bestmögliche Codetabelle.
    \end{satz}
    \begin{proof} % TODO stimmt des letzt mit contradiction?????
        \textit{Induktionsanfang}:
        Für $n \le r$ ist ein Huffman Baum offensichtlich optimal. \\
        \textit{Induktionshypothese}: Alle Huffman Bäume mit $< n$ Blättern sind optimal. \\
        \textit{Induktionsschritt}: Nun müssen wir zeigen, ein Huffman Baum $T$ mit $n$ Blättern optimal ist.
        Seien $l_0, l_1, \dots l_{r - 1}$ wieder die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit.
        Sei $Y$ der Knoten in $T$, dessen Kinder $l_0, l_1, \dots l_{r - 1}$ sind.
        Sei $T'$ nun ein Huffman Baum identisch zu $T$, bei dem $Y$ zu einem Blattknoten konvertiert wurde (mit der gleichen Antreffwahrscheinlichkeit wie der Knoten $Y$ in $T$).
        Aufgrund der Induktionshypothese ist $T'$ optimal, da er $n - (r - 1) < n$ Blätter hat.\\
        Wenn $T$ nicht optimal wäre, gäbe es einen Baum $T_1$ mit geringeren Kosten als $T$. Aus $T_1$ könnte man wieder einen Baum $T_1'$ mit $n - (r - 1)$ Blättern erstellen, in dem man $Y$ zu einem Knoten konvertiert. Wenn $T_1$ geringere Kosten als $T$ hätte, hätte auch $T_1'$ geringere Kosten als $T'$, woraus man schließen kann, dass $T$ optimal sein muss.
    \end{proof}

    \subsubsection{Pseudocode}

    \subsubsection{Laufzeit}

    \subsection{TODO Titel}
    TODO entweder bei 1 anfangen und bis r oder bei 0 anfagnen und bis r-1
    Im Aufgabenteil b) haben die Perlen $o_1, \cdot, o_r$ unterschiedliche, ganzzahlige Durchmesser $c_1, \cdot, c_r$. Wir sortieren die Perlen ab jetzt so, dass gilt: $c_1 \le c_2 \le \dots \le c_r = C$ und wir bezeichnen den Durchmesser der größten Perle $c_r$ mit $C$. \\
    Wir eine Codetabelle, die mit unterschiedlich großen Perlen erstellt wurde ähnlich wie in Aufgabenteil a) wieder als Baum darstellen.
    \begin{definition}
        Wir bezeichnen die Tiefe eines Knotens $V$ mit $depth(V)$. Die Tiefe des Wurzelknotens ist 0.
    \end{definition}
    Bis jetzt waren die Kinder $v_0$ bis $v_{r-1}$ eines Knotens $V$ immer genau eine Ebene tiefer als $V$, also $depth(v_i) = depth(V) - 1$.
    Wir wollen die Eigenschaft, dass die Pfadlänge von der Wurzel eines Baumes zu einem Blatt $|w|$ der Länge der entsprechenden Aneinanderreihung an Perlen entspricht aber natürlich weiterhin erhalten. Wenn wir also die Kinder $v_0$ bis $v_{r-1}$ des Knotens $V$ mit den Perlen $o_1$ bis $o_{r}$ beschriften $v_i \to o_i$, soll gelten: $depth(V) = depth(v_i) + c_i$.
    % TODO Bild  

    \subsubsection{Huffman}
    Da die oben beschriebene Huffman-Codierung den Spezialfall $c_1 = c_2 = \cdot = c_r$ darstellt, ist es zunächst sinnvoll, zu betrachten, weshalb der Huffman Algorithmus hier keinen optimalen Baum liefert.
    TODO (Die tiefsten Knoten sind nicht zwingend Nachbarn, weil c1 = c2 etc)

    \subsubsection{Vollständige Bäume}
    TODO Quelle hier (TODO vlt kuuz auf Paper eingehen) Der und der haben 19irgendwas einen neuen Ansatz vorgestellt... sehr ausführlich hier fokusssiert auf das wesentliche) \\
    Da es in diesem Aufgabenteil also nicht möglich ist, die Bäume von unten nach oben mit einem Greedy-Algorithmus zu erstellen, müssen wir alle mögliche Lösungen betrachten.
    In diesem Kapitel werden wir uns zuerst auf vollständige Bäume beschränken, indem wir ähnlich wie in Teil a) fehlende Buchstaben durch Platzhalter mit Frequenz 0 ersetzen:
    \begin{definition}
        Für jeden Baum $T$ erhält man einen vollständigen Baum $Fill(T)$, indem man an jeden Knoten so viele zusätzliche Blätter mit Frequenz 0 hinzufügt, das dieser genau $r$ Blätter besitzt.
    \end{definition}
    \begin{figure}[H]
        \centering
        \begin{minipage}{.5\textwidth}
            \centering
            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 5mm, % sibling distance
                }
                [
                [
                [$\frac 1 5$, tier=2, [,phantom,tier=3]]
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=3]
                ]
                [
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=2]
                ]
                ]
            \end{forest}
            \captionof{figure}{Ein nicht vollständiger Baum $T$}
            \label{fig:test1}
        \end{minipage}%
        \begin{minipage}{.5\textwidth}
            \centering
            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 10mm, % sibling distance
                }
                [
                [
                [$\frac 1 5$, tier=2, [,phantom,tier=3]]
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=3]
                ]
                [
                [$\frac 1 5$, tier=2]
                [$\frac 1 4$, tier=2]
                [$0$, tier=3]
                ]
                [$0$, tier=2]
                ]
            \end{forest}
            \captionof{figure}{Der vervollständige Baum $Fill(T)$}
            \label{fig:test2}
        \end{minipage}
    \end{figure}



    \begin{lemma}
        Sei $T$ ein optimaler Baum mit $n$ Blättern. Die Anzahl der Blätter $m$ von $Fill(T)$ beträgt höchstens $m \le n(r-1)$.
    \end{lemma}
    \begin{proof}
        TODO
    \end{proof}
    Da $cost(Fill(T))$ = $cost(T)$ offensichtlich gilt, können wir nun das Problem umformulieren:\\
    Finde für die Perlendurchmesser $c_1, \dots, c_r$ und die Frequenzen $p_1 \ge \dots \ge p_n$ (und $p_i = 0$ für alle $i > n$) den vollen Baum $T_{opt}$ mit $m$ Blättern ($n \le m \le n(r - 1)$) mit minimalen Kosten:
    \[cost(T_{opt}) = \min \{cost(T) : T \text{ ist vollständig und hat $m$ Blätter ($n \le m \le n(r - 1)$)}\}\]
    Wenn wir $T_{opt}$ konstruiert haben, können wir die Blätter mit Frequenz 0 entfernen und erhalten eine optimale Codierungstabelle für $n$ Buchstaben. \\
    Dafür müssen wir aber zuerst betrachten, wie wir vollständige Bäume allgemein darstellen und Ebene für Ebene konstruieren können.

    \begin{definition}
        TODO braucht man des und wenn ja hier?
        Wir nennen einen Baum Ebene-$i$-Baum, wenn alle internen Knoten auf einer Ebene $\le i$ liegen. \\
    \end{definition}
    \begin{definition}
        Wir kürzen einen Baum $T$ zu dem Ebene-$i$-Baum $Cut_i(T)$, indem wir alle Knoten entfernen, deren Eltern Tiefer als Ebene-$i$ liegen: \[Cut_i(T) = T - {v \in T \mid |parent(v)| > i}\]
    \end{definition}
    TODO Beispiel

    \begin{definition}
        Die Signatur einer Ebene $i$ des Baums $T$ ist das $C + 1$-Tupel \[sig_i(T) = (m;l_1,l2_, \dots, l_C)\]
        wobei $m = |\{v \in T \mid v \text{ ist ein Blatt, tiefe} (v) \le i\}|$ der Anzahl der Blätter von $T$ mit einer Tiefe von höchstens $i$ enspricht und
        \[l_k = |\{u \in T \mid \text{tiefe}(u) = i + k\}, k \in \{1,\dots,C\}\]
        die Anzahl der Knoten auf Ebene $i + k$ ist.
    \end{definition}
    Diese Signatur wird es uns später erlauben, alle möglichen zu betrachten und dabei aber kleine Unterschiede, die nichts an den Kosten eines Baums ändern zu vernachlässigen.


    TODO Beispiele mit signatur und expand

    Über die Signatur einer eines Ebene-$i$-Baums können wir nun die Kosten dieser Ebene definieren, was uns später dabei helfen wird, den \glqq Billigsten\grqq{} Baum zu finden.
    \begin{definition}
        Sei $T$ ein Ebene-$i$ Baum mit der Signatur $sig_i(T) = (m, l_1, l_2, \dots, l_C)$. Für $m \le n$ definieren wir die Kosten der Ebene-$i$ als:
        \[cost_i(T) = \sum^m_{j=1} |w_j| \cdot p_j + i \cdot \sum^n_{j=m + 1}p_j\]
        wobei $|w_1| \le \cdot \le |w_m|$ die $m$ höchsten Blätter nach Tiefe geordnet sind.
    \end{definition}
    %    TODO igendwo explizit sagen, dass $|w_i| $tiefe vom blatt
    Der erste Term der Summe beschreibt Kosten der Blätter, für die bereits sicher ist, dass es sich um Blätter handelt, während der zweite Term die Kosten für die übrigen Blätter um die Ebene $i$ zu erreichen darstellt.
    FÜr $m \ge n$ erübrigt sich der zweite Term, da $p_i = 0$ für $i > m$. D.h. wenn $T$ ein Ebene-$i$-Baumm mit $sig_i(T) = (m, l1, \dots l_C)$ ist und $m \ge n$, dann gilt $cost_i(T) = cost(T)$. \\
    \begin{definition}
        Sei $(m, l1, \dots, l_C)$ eine valide Signatur. Wir bezeichnen die minimalen Kosten eines Baumes mit dieser Signatur mit $OPT[m, l1, \dots l_C]$: \[OPT[m,l1, \dots, l_C] = \min \{cost_i(T) \mid \text{$T$ ist ein Ebene-$i$-Baum mit $sig_i(T) = (m, l_1, \dots, l_C)$}\}\]
    \end{definition}
    Da die maximale Anzahl an Blättern des optimalen vervollständigen Baums $Fill(T_{opt})$ $n(r-1)$ beträgt, entsprechen die Kosten dieses Baums dem Minimum aller Kosten $OPT[m, l1, \dots, l_C]$ mit $m \ge n$ und $m + l_1 + \dots + l_C \le n(r-1)$:
    \[cost(Fill(T_{opt}))) = cost(T_{opt}) = \min  \{OPT[m, l1, \dots, l_C] \mid m \ge n \land m + l_1 + \dots + l_C \le n(r-1)\}.\]
    Um dieses Minimum zu ermitteln müssen wir die $OPT$-Tabelle Schritt für Schritt auffüllen, beginnend bei einem Ebene-0-Baum, der nur aus der Wurzel und dessen Kindern besteht.
    Sei $T$ also ein Ebene-$i$-Baum und $T'$ ein Ebene-$i+1$-Baum, der bis auf Ebene-$i$ identisch zu $T$ ist, also: $Cut_i(T') = T$. $T$ und $T'$ haben also die selbe Anzahl an Knoten auf den Ebenen $0$ bis $i$. Daher ist auch die Anzahl der Knoten auf Ebene $i+1$ identisch, der einzige Unterschied besteht darin, ob diese Knoten Blätter oder interne Knoten sind. In $T$ sind alle diese Knoten Blätter, da $T$ ein Ebene-$i$-Baum ist. In $T'$ könnten auch alle Knoten auf Ebene $i+1$ Blätter sein, es könnte aber auch eine bestimmte Anzahl $q$ an Knoten interne Knoten sein, maximal aber natürlich so viele, wie $T$ Blätter in Ebene $i+1$ hat. Sei $sig_i(T) = (m, l_1, \dots, l_C)$ die Ebene-$i$ Signatur von $T$. Damit können wir sagen, dass $0 \le q \le l_1$, da $l_1$ die Anzahl der Blätter von $T$ auf Ebene $i+1$ ist.
    \begin{definition}
        Sei $T$ ein Ebene-$i$-Baum mit der Signatur $sig_T = (m;l_1,l_2,\dots,l_C)$. Die Expand Operation wandelt $0 \le q \le l_1$ Blätter auf Ebene $i + 1$ in interne Knoten um, indem $r$ Kinder an jedes dieser Blätter angehängt werden:
            \[T' = Expand_i(T, q)\]
    \end{definition}
    Die Expand-Operation legt nicht fest, welche der $l_1$ Blättern zu Knoten werden.
    Da wir uns auf vollständige Bäume beschränken, sind die Kosten dieser Bäume aber gleich, selbst wenn die Bäume selbst geringfügige Unterschiede haben. Um die Änderung der Signatur des Baums zu quantifizieren, müssen wir den charakteristischen Vektor einer Perlensammlung mit den Durchmessen $c_1, c_2, \dots, c_r$) definieren:
    \begin{definition}
        Der charakteristische Vektor $(d_1, d_2, \dots, d_C)$ einer Perlensammlung mit den Durchmessern $D = (c_1, c_2, \dots, c_r)$ entspricht den Anzahlen, wie oft ein bestimmter Durchmesser in der Perlensammlung vertreten ist:
        \[d_i = \text{Anzahl von $i$ in $D$}\]
    \end{definition}
    \begin{beispiel}
        Der charakteristische Vektor der Beispieldatei 7 mit den Durchmessern $D = (1, 1, 1, 1, 1, 1, 1, 2, 3, 4)$ beträgt $(7, 1, 1, 1)$ und der charakteristische Vektor der Beispieldatei 5 mit den Durchmessern $D = (1, 1, 2, 2, 3)$ beträgt $(2, 2, 1)$.
    \end{beispiel}
    \begin{lemma}
        Sei $T$ ein Ebene-$i$-Baum mit der Signatur $sig_T = (m;l_1,l_2,\dots,l_C)$ und $T' = Expand_i(T,q)$ die Erweiterung um $q$. Die Signatur von $T'$ ist dann: \[sig_{i+1}(T') = (m + l_1, l_2, \dots, l_C, 0)) + q \cdot (-1, d_1, d_2, \dots, d_C)\]
        (Multiplikation und Addition werden Elementweise ausgeführt). Die Kosten der Erweiterung betragen:
        \[cost_{i+1}(Expand_i(T,q)) = cost_i(T) + \sum_{m < j \le n}p_j\]
    \end{lemma}
    \begin{proof}
        TODO
    \end{proof}
    \begin{beispiel}
        TODO
    \end{beispiel}
    Wir können nun einen Graph $G = (V, E)$ definieren, dessen Knoten die Signaturen der Bäume darstellen und dessen Kanten Erweiterungen auf die nächste Ebene repräsentieren:
    \[V = \{(m, l_1, \dots, l_C) \mid  m, l_1, \dots, l_2 \ge 0 \land m + l_1 + \dots + l_c \le n(r-1)\}\]
    \[E = \{(S = (m, l_1, \dots, l_C), S') \in V \times V \mid \exists q, 0 \le q \le l_1, S' = (m + l_1, l_2, \dots, l_C, 0) + q \cdot (-1, d_1, \dots, d_C)\}\]
    In diesem Graph könnte man nun mithilfe von Breitensuche den Pfad finden, der zu


    TODO man könnte jetzt bfs machen kurz laufzeit und ist schlecht

    \subsection{TODO Titel}


    TODO Optimierung: kleinen Baum mit höhe h bauen (wo alle probabiliteis gleich sind) -> n Blätter -> im n dinger zusammenfassen dann algorithmus machen und kleine bäume wieder hinbasteln

    \section{Umsetzung}
    Hier wird kurz erläutert, wie die Lösungsidee im Programm tatsächlich umgesetzt wurde. Hier können auch Implementierungsdetails erwähnt werden.
    TODO erweiterung: die Kosten der Perlen sind keine ganzen Zahlen mehr, sondern reelle Zahlen.


    \section{Beispiele}
    Genügend Beispiele einbinden! Die Beispiele von der BwInf-Webseite sollten hier diskutiert werden, aber auch eigene Beispiele sind sehr gut – besonders wenn sie Spezialfälle abdecken. Aber bitte nicht 30 Seiten Programmausgabe hier einfügen!


    \section{Quellcode}
    Unwichtige Teile des Programms sollen hier nicht abgedruckt werden. Dieser Teil sollte nicht mehr als 2–3 Seiten umfassen, maximal 10.


\end{document}
