\documentclass[a4paper,10pt,ngerman]{scrartcl}
\usepackage{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[a4paper,margin=2.5cm,footskip=0.5cm]{geometry}

% Die nächsten drei Felder bitte anpassen:
\newcommand{\Aufgabe}{Aufgabe 1: Schmucknachrichten} % Aufgabennummer und Aufgabennamen angeben
\newcommand{\TeilnahmeId}{74749}                  % Teilnahme-ID angeben
\newcommand{\Name}{Christian Krause}             % Name des Bearbeiter / der Bearbeiterin dieser Aufgabe angeben


% Kopf- und Fußzeilen
\usepackage{scrlayer-scrpage, lastpage}
\setkomafont{pageheadfoot}{\large\textrm}
\lohead{\Aufgabe}
\rohead{Teilnahme-ID: \TeilnahmeId}
\cfoot*{\thepage{}/\pageref{LastPage}}

% Position des Titels
\usepackage{titling}
\setlength{\droptitle}{-1.0cm}

% Für mathematische Befehle und Symbole
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

% Für Bilder
\usepackage{graphicx}

% Für Algorithmen
\usepackage{algpseudocode}
\usepackage{algorithm}      % floating wrapper for algorithms

% Für Quelltext
\usepackage{listings}
\usepackage{color}

\usepackage{forest}
\usepackage{float}

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\lstset{
    keywordstyle=\color{blue},commentstyle=\color{mygreen},
    stringstyle=\color{mymauve},rulecolor=\color{black},
    basicstyle=\footnotesize\ttfamily,numberstyle=\tiny\color{mygray},
    captionpos=b, % sets the caption-position to bottom
    keepspaces=true, % keeps spaces in text
    numbers=left, numbersep=5pt, showspaces=false,showstringspaces=true,
    showtabs=false, stepnumber=2, tabsize=2, title=\lstname
}
\newtheorem{satz}{Satz}
\newtheorem{definition}[satz]{Definition}
\newtheorem{lemma}[satz]{Lemma}
\newtheorem{beispiel}[satz]{Beispiel}
\newtheorem{korollar}[satz]{Korollar}

\usepackage[%
    backend=biber,
    style=authortitle,
    sorting=nyt,
]{biblatex}
\addbibresource{main.bib}


% Diese beiden Pakete müssen zuletzt geladen werden
\usepackage[hidelinks]{hyperref} % Anklickbare Links im Dokument
\usepackage{cleveref}
\usepackage{comment}
\usepackage{stmaryrd}


% Daten für die Titelseite
\title{\textbf{\Huge\Aufgabe}}
\author{\LARGE Teilnahme-ID: \LARGE \TeilnahmeId \\\\
\LARGE Bearbeiter/-in dieser Aufgabe: \\
\LARGE \Name\\\\}
\date{\LARGE\today}

\begin{document}

    \maketitle
    \tableofcontents

    \section*{Zusammenfassung}
    Für den ersten Aufgabenteil a) verwende ich eine Verallgemeinerung der klassischen Huffman-Codierung, um eine optimale Codierungstabelle für die Perlen zu erstellen.
    Im Aufgabenteil b) beziehe ich mich auf ein Paper, das einen Ansatz zur Erstellung von optimalen Codetabellen für Perlen mit unterschiedlichem Durchmesser vorstellt.
    Anhand dieses Paper habe ich meinen eigenen Ansatz zur Erstellung von optimalen Bäumen erarbeitet, der in der Praxis deutlich schneller ist.

    \clearpage


    \section{Lösungsidee}

    \subsection{Huffman Codierung}
    David Huffman hat 1952 eine Methode veröffentlicht, die heute als \textit{Huffman Codierung} bekannt ist\autocite{noauthor_huffman-kodierung_2025}.
    Die Huffman Codierung kann verwendet werden, um eine optimale präfixfreie Codierung für einen bestimmten Text zu finden.
    Dabei geht man von einem Alphabet $A$ mit $n$ verschiedenen Zeichen $a_1, \dots, a_n \in A$ aus, gemeinsam mit der Häufigkeitsverteilung der Zeichen \[p_i = \frac {\text{Häufigkeit von $a_i$ im zu codierenden Text}} {\text{Länge des Textes.}}\]
    Man nennt diese Antreffwahrscheinlichkeit $p_i$ eines Zeichens auch \textit{Frequenz} oder \textit{Gewichtung}.
    Wir nehmen an, dass das Alphabet nach absteigender Häufigkeit sortiert ist, also $p_1 \ge p_1 \ge \dots \ge p_n$.
    Der Text soll mit einem Ausgabealphabet $O$ codiert werden, das aus $r$ verschiedenen Zeichen $o_1, \dots, o_r \in O$ besteht.
    In der Bwinf-Aufgabenstellung besteht dieses Ausgabealphabet $O$ aus den $r$ verschiedenen Perlen (die aber alle den gleichen Durchmesser haben). Um den ursprünglichen Text zu codieren, müssen wir nun jedem Buchstaben $a_i$ ein \textit{Codewort} $w_i$ zuordnen, das aus einer Kette an Buchstaben aus dem Ausgabealphabet besteht $w_i = o_j o_k o_l \dots$. \\
    Diese Codierung soll \textit{präfixfrei} sein, also kein Codewort soll Teil eines anderen Codeworts sein.
    Dadurch kann der Text als Aneinanderreihung von Codewörtern (ohne \glqq Komma\grqq~dazwischen) übertragen und eindeutig decodiert werden. \\
    Aufgrund von dieser Eigenschaft können wir den Code als einen Baum darstellen, der $n$ Blätter hat und bei dem jeder Knoten höchstens $r$ Kinder hat.
    \begin{definition}
        Wir nennen einen solchen Baum mit $n$ blättern und höchstens $r$ Kindern pro Knoten \textbf{valide}, da er eine mögliche Codetabelle darstellt.
    \end{definition}
    Jedes Blatt eines solchen Baums repräsentiert ein Codewort $w$, das eindeutig durch den Pfad von der Wurzel des Baums zu diesem Blatt definiert ist. Der Pfad wird durch die Kanten des Baums definiert, die mit den Perlen beschriftet sind. Da alle Perlen gleich groß sind, also die Länge aller Buchstaben des Ausgabealphabets gleich ist, ist die Beschriftung der Kanten beliebig. Es ist lediglich wichtig, dass alle Kanten eines Knotens mit unterschiedlichen Perlen beschriftet sind. Die Länge des Codeworts $|w|$ entspricht der Anzahl der Kanten auf dem Pfad von der Wurzel zu diesem Blatt. \\
    Da wir eine optimale Codetabelle (also eine möglichst kurze Perlenkette) erstellen wollen, müssen wir die \glqq Kosten\grqq~eines Baums definieren.
    Diese Kosten eines Baums hängen natürlich auch davon ab, welches Codewort welchem Buchstaben zugeordnet wird. Für diese Definition gehen wir
    davon aus, dass wir eine solche Zuordnung $w_i \to a_i$ haben.
    \begin{definition}
        Die Kosten eines Baums $T$ sind definiert als das Produkt der Länge jedes Codeworts $w_i$ mit der Frequenz $p_i$ des codierten Buchstabens $a_i$: \[cost(T) = \sum_{i=0}^{i\le n} |w_i| \cdot p_i\]
    \end{definition}
    Da die Kosten eines Baumes proportional zu der Länge der resultierenden Perlenkette sind, kann die Aufgabenstellung darauf reduziert werden, den validen Baum $T$ mit den minimalen Kosten zu finden. \\
    \begin{definition}
        Wir nennen einen solchen Baum, der die minimalen Kosten (kürzeste Perlenkette) für eine bestimmte Häufigkeitsverteilung hat, \textbf{optimal}.
    \end{definition}
    Für die Kosten eines Baums ist aber auch die Zuordnung, welcher Buchstabe von welchem Codewort codiert werden soll, entscheidend.
    Für diese Aufgabenstellung ist die Zuordnung aber für jeden Baum eindeutig, da wir die Kosten des Baums minimieren wollen.
    Um das zu erreichen, müssen wir das längste Codewort dem Buchstaben zuordnen, der am seltensten vorkommt, und das kürzeste Codewort dem Buchstaben zuordnen, der am häufigsten vorkommt.
    Dafür ordnen wir im Folgenden die Blätter Baums in aufsteigender Reihenfolge, also $|w_1| \le \dots \le |w_n|$.
    Da das Alphabet nach absteigender Reihenfolge sortiert ist, also $p_1 \ge \dots \ge p_n$, liefert die Zuordnung von $w_i$ zu $a_i$ für jeden Baum die geringsten Kosten. \\

    \subsubsection{Konstruktion des optimalen Baums}
    \begin{definition}
        Wir nennen einen $r$-när Baum, bei dem jeder Knoten maximal $r$ Kinder hat \textbf{vollständig}, wenn jeder Knoten genau $r$ Kinder hat.
    \end{definition}
    \begin{lemma}
        Ein optimaler binärer Huffman Baum ist vollständig.
    \end{lemma}
    \begin{proof}
        Ein optimaler binärer Huffman Baum ist im Allgemeinen vollständig, da in einem optimalen Baum kein Knoten mit nur einem Kind existieren kann.
        Würde man diesen Knoten zu einem Blatt machen, hätte man einen Baum mit der gleichen Anzahl an Blättern aber geringeren Kosten.
    \end{proof}
    Das gilt im allgemeinen Fall bei Bäumen mit $r > 2$ Kindern aber nicht.
    Für die allgemein bekannte Konstruktion eines binären Huffman Baums werden wiederholt zwei Teilbäume zu einem zusammengefasst, bis schließlich nur noch einer übrig ist.
    Im allgemeinen Fall müssen immer $r$ Teilbäume zu einem zusammengefasst werden, was aber nicht für jede Anzahl an Buchstaben $n$ im Alphabet immer funktioniert.
    \begin{beispiel}
        Für $n = 4$ und $r = 3$ werden im ersten Schritt drei Knoten zu einem zusammengefasst. Im nächsten sind nur noch zwei Knoten übrig. Würde man diese Knoten nun zu einem fertigen Baum kombinieren wäre dieser für bestimmte Häufigkeitsverteilungen (z.B. $p_0 = p_1 = p_2 = p_3$) nicht optimal (Siehe Abbildung).
        \begin{figure}
            \label{tree:mit_platzhalter}

            \centering
            \begin{minipage}{.5\textwidth}
                \label{tree:suboptimal}

                \centering
                \begin{forest}
                    for tree={
                        grow                    = south,
                        parent anchor           = north,
                        child anchor            = north,
                        edge                    = {thick, -},
                        l sep                    = 10mm, % level distance
                        s sep                    = 5mm, % sibling distance
                    }
                    [
                    [
                    [$0.25$, tier=2]
                    [$0.25$, tier=2]
                    [$0.25$, tier=3]
                    ]
                    [$0.25$]
                    ]
                \end{forest}
                \captionof{figure}{Suboptimaler Baum}
            \end{minipage}%
            \begin{minipage}{.5\textwidth}
                \centering
                \begin{forest}
                    for tree={
                        grow                    = south,
                        parent anchor           = north,
                        child anchor            = north,
                        edge                    = {thick, -},
                        l sep                    = 10mm, % level distance
                        s sep                    = 10mm, % sibling distance
                    }
                    [
                    [
                    [$0.25$, tier=2]
                    [$0.25$, tier=2]
                    [$0$, tier=3]
                    ]
                    [$0.25$]
                    [$0.25$]
                    ]
                \end{forest}
                \captionof{figure}{Optimaler Baum mit Platzhalterknoten}
            \end{minipage}
        \end{figure}
    \end{beispiel}
    Daher muss das Alphabet zuerst mit so vielen Platzhalterbuchstaben, deren Antreffwahrscheinlichkeit 0 ist, aufgefüllt werden, dass gilt: $n \mod (r - 1) = 1$.
    Da bei jeder Iteration, bei der $r$ Knoten zu einem zusammengefasst werden, die Gesamtanzahl der Knoten um $r-1$ reduziert wird, stellt diese Formel sicher, dass am Ende genau ein Knoten übrig bleibt.
    Die Konstruktion läuft nun mit einem Greedy-Algorithmus ab:
    \begin{enumerate}
        \item Erstelle für jeden Buchstaben $a_i$ im Alphabet (inklusive Platzhalter) einen Teilbaum (der aus einem Wurzelknoten besteht) und beschriften diesen mit der Frequenz $p_i$ des Buchstabens $a_i$.
        \item Wähle die $r$ Teilbäume mit den kleinsten Antreffwahrscheinlichkeiten. (Diese Wahl ist nicht eindeutig)
        \item Beschrifte einen neuen Knoten mit der Summe der Antreffwahrscheinlichkeiten der $r$ gewählten Teilbäume und erstelle einen neuen Teilbaum mit dem neuen Knoten als Wurzel und den gewählten Teilbäumen als Kinder.
        \item Wiederhole Schritt 2 und 3, bis nur noch ein Baum übrig ist.
    \end{enumerate}
    Aufgrund der Platzhalterknoten entsteht nun ein optimaler, vollständiger Baum (siehe Abbildung).

    \subsubsection{Beweis der Optimalität}
    Der Standartbeweis für die Optimalität von binären Huffman Bäumen kann leicht verallgemeinert werden.
    Dazu müssen wir zuerst das \glqq Sibling-Lemma\grqq~auf $r-$när Bäume verallgemeinern:
    \begin{lemma}
        Seien $l_1, l_2, \dots l_r$ die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit (In dieser Auswahl können auch die Platzhalterbuchstaben enthalten sein).
        Sie sind in einem Huffman Baum \glqq Geschwister\grqq, also Kinder des gleichen Knotens $Y$ und liegen auf der untersten Ebene des Baums.
    \end{lemma}
    \begin{proof}
        Die Buchstaben $l_1, \dots l_r$ sind sicher Geschwister, da sie als erstes ausgewählt werden. \\
        Wenn $l_1, \dots l_r$ nicht auf der untersten Ebene des Baums liegen würden, dann müsste es einen internen Knoten $X$ geben, dessen Antreffwahrscheinlichkeit kleiner ist als die des Knotens $Y$, dessen Kinder $l_1, \dots l_r$ sind.
        Da der Baum vollständig ist, müsste aber mindestens einer der Kinder von $X$ eine geringere Antreffwahrscheinlichkeit haben als einer der Kinder  $l_1, \dots l_r$ von $Y$.
        Das widerspricht aber unserer anfänglichen Annahme, dass $l_1, \dots l_r$ die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit sind. Daher können wir sagen, dass $l_1, \dots l_r$ immer auf der untersten Ebene des Baums liegen.
    \end{proof}
    Damit können wir nun mithilfe von Induktion über die Größe $n$ des Alphabets den Beweis durchführen:
    \begin{satz}
        Die oben beschriebene Konstruktion für $r-$näre Huffman Bäume liefert einen optimalen Baum und damit eine bestmögliche Codetabelle.
    \end{satz}
    \begin{proof}
        \textit{Induktionsanfang}:
        Für $n \le r$ ist ein Huffman Baum offensichtlich optimal. \\
        \textit{Induktionshypothese}: Alle Huffman Bäume mit $< n$ Blättern sind optimal. \\
        \textit{Induktionsschritt}: Nun müssen wir zeigen, dass ein Huffman Baum $T$ mit $n$ Blättern optimal ist.
        Seien $l_1, \dots l_r$ wieder die $r$ Buchstaben mit der geringsten Antreffwahrscheinlichkeit und $Y$ der Knoten in $T$, dessen Kinder $l_1, \dots l_r$ sind.
        Sei $T'$ nun ein Huffman Baum identisch zu $T$, bei dem $Y$ zu einem Blattknoten konvertiert wurde (mit der gleichen Antreffwahrscheinlichkeit wie der Knoten $Y$ in $T$).
        Aufgrund der Induktionshypothese ist $T'$ optimal, da er $n - (r - 1) < n$ Blätter hat.\\
        Wenn $T$ nicht optimal wäre, gäbe es einen Baum $T_1$ mit geringeren Kosten als $T$. Aus $T_1$ könnte man wieder einen Baum $T_1'$ mit $n - (r - 1)$ Blättern erstellen, in dem man $Y$ zu einem Knoten konvertiert. Wenn $T_1$ geringere Kosten als $T$ hätte, hätte auch $T_1'$ geringere Kosten als $T'$ (also wäre $T'$ nicht optimal).
        Da das unserer Induktionshypothese widerspricht, können wir daraus schließen, dass $T$ optimal sein muss.
    \end{proof}

    \subsubsection{Pseudocode}

    \begin{algorithm} [H]
        \caption{\textsc{ErstelleHuffmanBaum}\,(r, A, p)}
        \label{alg:huffman-r-ary}
        \begin{algorithmic}[1]
            \Function{ErstelleHuffmanBaum}{$r, A, p$}
                \State /* $r$: max. Kinder pro Knoten; $A$ Alphabet; $p[a]$: Frequenz von Symbol $a$ */
                \State Initialisiere MinHeap $H$
                \ForAll{$a \in A$}
                    \State Erzeuge Blattknoten $node$ mit $node.\text{symbol}\!=\!a$ und $node.\text{freq}\!=\!p[a]$
                    \State $H.\text{push}(node)$
                \EndFor
                \State $n \gets |A|$, \quad $m \gets 0$
                \While{$(n + m) \bmod (r-1) \neq 1$}
                    \State Erzeuge Platzhalter‐Blatt $z$ mit $z.\text{freq}=0$
                    \State $H.\text{push}(z)$
                    \State $m \gets m + 1$
                \EndWhile

                \While{$H.\text{size}() > 1$}
                    \State /* Ziehe die $r$ Bäume mit der kleinsten Frequenz aus dem Heap */
                    \State $C \gets [\ ]$ \Comment{Die Kinder des neuen Knotens}
                    \For{$i = 1$ \textbf{to} $r$}
                        \State $C.\text{append}(H.\text{pop}())$
                    \EndFor
                    \State /* Erzeuge neuen inneren Knoten als Wurzel dieser $r$ Kinder */
                    \State $new\_node.\text{freq} \gets \sum_{c \in C} c.\text{freq}$
                    \State $new\_node.\text{children} \gets C$
                    \State $H.\text{push}(new\_node)$
                \EndWhile

                \State \Return $H.\text{pop}()$  \Comment{Wurzel des fertigen Huffman-Baums}
            \EndFunction
        \end{algorithmic}
    \end{algorithm}

    \subsubsection{Laufzeit}
    Die Laufzeitbetrachtung verläuft ähnlich wie bei binären Huffman Bäumen\autocite{noauthor_huffman-kodierung_2025}:\\
    Sei $n$ die Länge des Alphabets und $t$ die Länge des Originaltextes.
    Um die Frequenzen der Buchstaben zu bestimmen, muss der Text einmal durchlaufen werden.
    Diese Funktion, die im Pseudocode oben nicht aufgeführt ist, hat also eine asymptotische Laufzeit von $O(t)$.
    Die For-Schleife, die für jeden Blattknoten einen Buchstaben erzeugt, hat eine Laufzeit von $O(n)$. Da $n < t$ erhöht diese For-Schleife die asymptotische Laufzeit aber nicht.
    Die While-Schleife, die Platzhalterknoten einfügt, iteriert höchstens $(r-1)$ mal. Da $r < n$ (sonst wäre die Codierung trivial) trägt diese While-Schleife auch nicht zur Asymptotischen Laufzeit bei.\\
    In der Haupt-While-Schleife wird der Heap mit einer anfänglichen Größe von $O(n)$ in jeder Iteration um $r-1$ verkleinert, sie hat also eine Laufzeit von $O(\frac n r)$.
    In der Schleife werden $r$ Knoten aus dem Heap gezogen und einer wieder eingefügt, jeweils mit einer Laufzeit von $O(\log n)$.
    Der innere Teil der While-Schleife hat also eine Laufzeit von $O(r \cdot \log n)$ und damit gilt für die Laufzeit der While-Schleife: $O(n \cdot \log n)$.
    Das gesamte Programm hat also eine asymptotische Laufzeit von $O(t + n \cdot \log n)$

    \subsection{Ungleiche Perlengrößen}
    Im Aufgabenteil b) haben die Perlen unterschiedliche, ganzzahlige Durchmesser $c_1, \dots, c_r$. Wir sortieren die Perlen ab jetzt so, dass gilt: $c_1 \le c_2 \le \dots \le c_r = C$ und wir bezeichnen den Durchmesser der größten Perle $c_r$ mit $C$. \\
    Wir können eine Codetabelle, die mit unterschiedlich großen Perlen erstellt wurde ähnlich wie in Aufgabenteil a) wieder als Baum darstellen.
    \begin{definition}
        Wir bezeichnen die Tiefe eines Knotens $V$ mit $|V|$. Die Tiefe des Wurzelknotens ist 0.
    \end{definition}
    Bis jetzt waren die Kinder $v_1$ bis $v_r$ eines Knotens $V$ immer genau eine Ebene tiefer als $V$, also $|v_i| = |V| - 1$.
    Wir wollen die Eigenschaft, dass die Pfadlänge von der Wurzel eines Baumes zu einem Blatt $|w|$ der Länge der entsprechenden Aneinanderreihung an Perlen entspricht aber natürlich weiterhin erhalten. Wenn wir also die Kinder $v_1$ bis $v_r$ des Knotens $V$ mit den Perlen $o_1$ bis $o_{r}$ beschriften $v_i \to o_i$, soll gelten: $|V| = |v_i| + c_i$.
    Daraus resultieren sogenannte \textit{schiefe} (engl. lopsided) Bäume (Siehe Abbildung \ref{fig:test1}). \\
    Die oben beschriebene Huffman-Codierung deckt den Spezialfall $c_1 = c_2 \dots = c_r$ ab, im allgemeinen Fall produziert sie jedoch keine optimalen Bäume.
    Das liegt dran, dass sich der Beweis für die Optimalität von Huffman-Bäumen darauf stützt, dass die $r$ tiefsten Knoten Geschwister sind.
    Das ist in einem schiefen Baum im Allgemeinen aber nicht der Fall.

    \subsubsection{Vollständige Bäume}
    Golin und Rote stellen 1998 in ihrem Paper \glqq A dynamic programming algorithm for constructing optimal prefix-free codes with unequal letter costs\grqq\autocite{golin_dynamic_1998}~ einen neuen Ansatz zur Berechnung von optimalen Präfixfreien Codes für unterschiedliche Kosten der Buchstaben vor.
    Da das dem Problem in Aufgabenteil b) entspricht, orientiere ich mich in den folgenden Kapiteln an diesem Paper.
    Es ist aber anzumerken, dass meine Algorithmen nicht genau denen im Paper entsprechen, sondern durch einen etwas anderen Ansatz in der Praxis deutlich schneller sind.
    Am Ende diskutiere ich diese Unterschiede noch genauer.\\
    Da es in diesem Aufgabenteil also nicht möglich ist, die Bäume von unten nach oben mit einem Greedy-Algorithmus zu erstellen, müssen wir alle mögliche Lösungen betrachten.
    In diesem Kapitel werden wir uns zuerst auf vollständige Bäume beschränken, indem wir ähnlich wie in Teil a) fehlende Buchstaben durch Platzhalter mit Frequenz 0 ersetzen:
    \begin{definition}
        Für jeden Baum $T$ erhält man einen vollständigen Baum $Fill(T)$, indem man an jeden Knoten so viele zusätzliche Blätter mit Frequenz 0 hinzufügt, dass dieser genau $r$ Blätter besitzt.
    \end{definition}
    \begin{figure}[H]
        \centering
        \begin{minipage}{.5\textwidth}
            \centering
            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 5mm, % sibling distance
                }
                [
                [
                [$\frac 1 5$, tier=2, [,phantom,tier=3]]
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=3]
                ]
                [
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=2]
                ]
                ]
            \end{forest}
            \captionof{figure}{Ein nicht vollständiger Baum $T$}
            \label{fig:test1}
        \end{minipage}%
        \begin{minipage}{.5\textwidth}
            \centering
            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 10mm, % sibling distance
                }
                [
                [
                [$\frac 1 5$, tier=2, [,phantom,tier=3]]
                [$\frac 1 5$, tier=2]
                [$\frac 1 5$, tier=3]
                ]
                [
                [$\frac 1 5$, tier=2]
                [$\frac 1 4$, tier=2]
                [$0$, tier=3]
                ]
                [$0$, tier=2]
                ]
            \end{forest}
            \captionof{figure}{Der vervollständige Baum $Fill(T)$}
            \label{fig:test2}
        \end{minipage}
    \end{figure}



    \begin{lemma}
        Sei $T$ ein optimaler Baum mit $n$ Blättern. Die Anzahl der Blätter $m$ von $Fill(T)$ beträgt höchstens $m \le n(r-1)$.
    \end{lemma}
    \begin{proof}
        In einem optimalen Baum hat jeder Knoten mindestens zwei Kinder (Sonst könnte man einen Knoten mit nur einem Kind zu einem Blatt machen und würde einen Baum mit geringeren Kosten erhalten). Die Anzahl der internen Knoten in einem vollständigen Binärbaum mit $n$ Blättern beträgt $I = n - 1$, also hat ein optimaler Baum höchstens $I$ interne Knoten.
        Ein vollständiger Baum mit $I$ internen Knoten hat genau $Ir - I + 1 = (r-1)I + 1$ Blätter, $Fill(T_{opt})$ hat also höchstens $1 + (n -1)(r-1) \le n(r-1)$ Blätter.
    \end{proof}
    Da $cost(Fill(T))$ = $cost(T)$ offensichtlich gilt, können wir nun das Problem umformulieren:\\
    Finde für die Perlendurchmesser $c_1, \dots, c_r$ und die Frequenzen $p_1 \ge \dots \ge p_n$ (und $p_i = 0$ für alle $i > n$) den vollen Baum $T_{opt}$ mit $m$ Blättern ($n \le m \le n(r - 1)$) mit minimalen Kosten:
    \[cost(T_{opt}) = \min \{cost(T) : T \text{ ist vollständig und hat $m$ Blätter ($n \le m \le n(r - 1)$)}\}\]
    Wenn wir $T_{opt}$ konstruiert haben, können wir die Blätter mit Frequenz 0 entfernen und erhalten eine optimale Codierungstabelle für $n$ Buchstaben. \\
    Dafür müssen wir aber zuerst betrachten, wie wir vollständige Bäume allgemein darstellen und Ebene für Ebene konstruieren können.

    \begin{definition}
        Wir nennen einen Baum Ebene-$i$-Baum, wenn alle internen Knoten auf einer Ebene $\le i$ liegen. \\
    \end{definition}
    \begin{definition}
        Wir kürzen einen Baum $T$ zu dem Ebene-$i$-Baum $Cut_i(T)$, indem wir alle Knoten entfernen, deren Eltern tiefer als Ebene-$i$ liegen: \[Cut_i(T) = T - \{v \in T \mid |parent(v)| > i\}\].
    \end{definition}
    \begin{definition}
        Die Signatur einer Ebene $i$ des Baums $T$ ist das $C + 1$-Tupel \[sig_i(T) = (m, l_1,l2_, \dots, l_C)\]
        wobei $m = |\{v \in T \mid v \text{ ist ein Blatt und } |v| \le i\}|$ der Anzahl der Blätter von $T$ mit einer Tiefe von höchstens $i$ enspricht und
        \[l_k = |\{u \in T \mid |u| = i + k\}| \text{~~~für alle } k \in \{1,\dots,C\}\]
        die Anzahl der Knoten auf Ebene $i + k$ ist.
    \end{definition}
    Diese Signatur wird es uns später erlauben, alle möglichen Bäume zu betrachten und dabei aber kleine Unterschiede, die nichts an den Kosten eines Baums ändern, zu vernachlässigen.

    \begin{beispiel}
        Sei $T = Cut_2(T)$ ein Ebene-2-Baum mit $c_1 = c_2 = 1, c_3 = 2$ und der Signatur $sig_2(T) = (3, 6, 2)$ (links).
        In der Mitte sieht man den Baum $Cut_1(T)$ mit der Signatur $sig_1(Cut_1(T)) = (0, 5, 2)$.
        Ganz rechts sieht man den Baum $Cut_0(T)$ mit der Signatur $sig_0(Cut_0(T)) = (0, 1, 2)$.
        \begin{figure}[H]

            \centering

            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 5mm, % sibling distance
                }
                [,phantom, [[
                [, tier=2, [,phantom,tier=3]]
                [, tier=2, [, [,phantom, tier=4]] [] [,tier=4]]
                [, tier=3]
                ]
                [
                [, tier=2]
                [, tier=2]
                [, tier=3]
                ]
                [, tier=2,[, [,phantom, tier=4]] [] [,tier=4]]
                ]
                [
                [
                [, tier=2, [,phantom,tier=3]]
                [, tier=2]
                [, tier=3]
                ]
                [
                [, tier=2]
                [, tier=2]
                [, tier=3]
                ]
                [, tier=2]
                ]
                [
                []
                [ [, phantom, tier=2]]
                [, tier=2]
                ]]
            \end{forest}%

        \end{figure}
    \end{beispiel}


    Über die Signatur eines Ebene-$i$-Baums können wir nun die Kosten dieser Ebene definieren, was uns später dabei helfen wird, den \glqq billigsten\grqq{} Baum zu finden.
    \begin{definition}
        Sei $T$ ein Ebene-$i$ Baum mit der Signatur $sig_i(T) = (m, l_1, l_2, \dots, l_C)$. Für $m \le n$ definieren wir die Kosten der Ebene-$i$ als:
        \[cost_i(T) = \sum^m_{j=1} |w_j| \cdot p_j + i \cdot \sum^n_{j=m + 1}p_j\]
        wobei $|w_1| \le \dots \le |w_m|$ die $m$ höchsten Blätter nach Tiefe geordnet sind.
    \end{definition}
    Der erste Term der Summe beschreibt Kosten der Blätter, für die bereits sicher ist, dass es sich um Blätter handelt, während der zweite Term die Kosten für die übrigen Blätter, um die Ebene $i$ zu erreichen, darstellt.
    Für $m \ge n$ erübrigt sich der zweite Term, da $p_i = 0$ für $i > n$. D.h. wenn $T$ ein Ebene-$i$-Baumm mit $sig_i(T) = (m, l1, \dots l_C)$ ist und $m \ge n$, dann gilt $cost_i(T) = cost(T)$. \\
    Um nun den \glqq billigsten\grqq~Baum zu finden, konstruieren wir die Bäume Ebene für Ebene, beginnend bei dem \textit{Wurzel-Baum}, der nur aus der Wurzel und deren Kindern besteht.
    Um die Signatur des Wurzel-Baums darzustellen, müssen wir zunächst den charakteristischen Vektor einer Perlensammlung definieren:
    \begin{definition}
        Der charakteristische Vektor $(d_1, d_2, \dots, d_C)$ einer Perlensammlung mit den Durchmessern $C = (c_1, c_2, \dots, c_r)$ entspricht den Anzahlen, wie oft ein bestimmter Durchmesser in der Perlensammlung vertreten ist:
        \[d_i = \text{Anzahl von $i$ in $C$}\]
    \end{definition}
    \begin{beispiel}
        Der charakteristische Vektor der Beispieldatei 7 mit den Durchmessern $C = (1, 1, 1, 1, 1, 1, 1, 2, 3, 4)$ beträgt $(7, 1, 1, 1)$ und der charakteristische Vektor der Beispieldatei 5 mit den Durchmessern $C = (1, 1, 2, 2, 3)$ beträgt $(2, 2, 1)$.
    \end{beispiel}
    \begin{definition}
        Der \textbf{Wurzel-Baum} $T_0$ ist der Ebene-0-Baum, der aus dem Wurzelknoten und dessen $r$ Kindern, die alle Blätter sind, besteht.
        Die Signatur des Wurzel-Baums ist: \[sig_0(T_0) = (0, d_1, d_2, \dots d_C)\] und $cost_0(T_0) = 0$.
    \end{definition}
    \begin{beispiel}
        Der Wurzel-Baum der Beispieldatei mit den Perlendurchmessern $C = (1, 1, 2, 2, 3)$ und dem charakteristischen Vektor $D = (2, 2, 1)$ sieht folgendermaßen aus:
        \begin{figure}[H]
            \centering
            \begin{forest}
                for tree={
                    grow                    = south,
                    parent anchor           = north,
                    child anchor            = north,
                    edge                    = {thick, -},
                    l sep                    = 10mm, % level distance
                    s sep                    = 5mm, % sibling distance
                }
                [[,[,phantom,tier=3]],
                [],
                [,tier=3],
                [,tier=3, [,phantom,tier=4]],
                [,tier=4]
                ]
            \end{forest}
        \end{figure}
    \end{beispiel}

    Sei $T$ also ein Ebene-$i$-Baum und $T'$ ein Ebene-$i+1$-Baum, der bis auf Ebene-$i$ identisch zu $T$ ist, also: $Cut_i(T') = T$. $T$ und $T'$ haben also die selbe Anzahl an Knoten auf den Ebenen $0$ bis $i$. Daher ist auch die Anzahl der Knoten auf Ebene $i+1$ identisch, der einzige Unterschied besteht darin, ob diese Knoten Blätter oder interne Knoten sind. In $T$ sind alle diese Knoten Blätter, da $T$ ein Ebene-$i$-Baum ist. In $T'$ könnten auch alle Knoten auf Ebene $i+1$ Blätter sein, es könnte aber auch eine bestimmte Anzahl $q$ an Knoten interne Knoten sein, maximal aber natürlich so viele, wie $T$ Blätter in Ebene $i+1$ hat. Sei $sig_i(T) = (m, l_1, \dots, l_C)$ die Ebene-$i$ Signatur von $T$. Damit können wir sagen, dass $0 \le q \le l_1$, da $l_1$ die Anzahl der Blätter von $T$ auf Ebene $i+1$ ist.
    \begin{definition}
        Sei $T$ ein Ebene-$i$-Baum mit der Signatur $sig_T = (m;l_1,l_2,\dots,l_C)$. Die Expand Operation wandelt $0 \le q \le l_1$ Blätter auf Ebene $i + 1$ in interne Knoten um, indem $r$ Kinder an jedes dieser Blätter angehängt werden:
        \[T' = Expand_i(T, q)\]
    \end{definition}
    Die Expand-Operation legt nicht fest, welche der $l_1$ Blättern zu Knoten werden.
    Da wir uns auf vollständige Bäume beschränken, sind die Kosten dieser Bäume aber gleich, auch wenn die Bäume selbst geringfügige Unterschiede haben.
    Um die Änderung der Signatur des Baums zu quantifizieren, können wir den charakteristischen Vektor einer Perlensammlung verwenden:

    \begin{lemma}
        Sei $T$ ein Ebene-$i$-Baum mit der Signatur $sig_T = (m;l_1,l_2,\dots,l_C)$ und $T' = Expand_i(T,q)$ die Erweiterung um $q$. Die Signatur von $T'$ ist dann: \[sig_{i+1}(T') = (m + l_1, l_2, \dots, l_C, 0) + q \cdot (-1, d_1, d_2, \dots, d_C)\]
        (Multiplikation und Addition werden Elementweise ausgeführt). Die Kosten der Erweiterung betragen:
        \[cost_{i+1}(Expand_i(T,q)) = cost_i(T) + \sum_{m < j \le n}p_j\]
    \end{lemma}
    \begin{proof}
        Die erste gleichung entsteht durch zwei Operationen: Das \glqq Verschieben\grqq\ der Signatur um eine Ebene nach unten und das Erweitern des Baums.
        \[sig_{i+1}' = (m + l_1, l_2, \dots, l_C, 0)\]
        Die Signatur $sig_{i+1}'$ ist das Ergebnis des Verschiebens.
        Bei der Erweiterung werden $q$ Blätter auf Ebene $i + 1$ zu internen Knoten umgewandelt, weshalb $q$ von der Anzahl dieser Blätter abgezogen wird.
        An diese neuen internen Knoten werden jeweils $r$ Blätter angehängt.
        Für jeden neuen internen Knoten entstehen daher $d_1$ neue Blätter auf Ebene $i+2$, $d_2$ neue Blätter auf Ebene $i+3$ usw.
        Daraus folgt die erste Gleichung. \\
        TODO

    \end{proof}
    \begin{beispiel}
        TODO
    \end{beispiel}

    \begin{definition}
        Wir bezeichnen zwei Bäume $T_1$ und $T_2$ als equivalent, wenn sie die gleiche Anzahl an Blättern auf jeder Ebene haben:
        \[T_1 = T_2\]
    \end{definition}
    \begin{korollar}
        Diese Äquivalenzrelation hat einige offensichtliche Eigenschaften:
        \begin{enumerate}
            \item Wenn $T_1 = T_2$, dann gilt $Expand_i(T_1, q) = Expand_i(T_2, q)$.
            \item Wenn $T_1 = T_2$, dann gilt $cost(T_1) = cost(T_2)$.
            \item Wenn $T_1 = T_2$, dann haben $T_1$ und $T_2$ auf jeder Ebene die gleiche Anzahl an internen Knoten.
        \end{enumerate}
    \end{korollar}
    \begin{lemma}
        Sei $T$ ein Ebene-$i$-Baum und $T'$ ein Ebene-$i+1$-Baum mit $Trunc_i(T') = T$.
        Es gibt ein $q$, sodass $Expand_i(T) = T'$.
    \end{lemma}
    \begin{proof}
        Folgt aus der Definition von $Expand_i$ und daraus, dass äquivalente Bäume auf jeder Ebene die gleiche Anzahl an internen Knoten haben.
    \end{proof}
    \begin{korollar}
        \label{lem:funktioniert}
        Jeder vollständige Ebene-$i$-Baum kann bis auf Äquivalenz durch $i$ Expand-Operationen vom Wurzel-Baum aus konstruiert werden.
    \end{korollar}
    Da $Fill(T_{opt})$ höchstens $n (r -1)$ Blätter hat, können wir $Fill(T_{opt})$ finden, indem wir vom Wurzel-Baum aus
    durch $Expand_i$ alle vollständigen Bäume durchsuchen, die $m \le (r - 1)$ Blätter haben.


    \begin{algorithm} [H]
        \caption{\textsc{GetOptimalTree1}\,(Frequenzen, Farbengrößen)}
        \label{alg:optimal_tree}
        \begin{algorithmic}[1]
            \Function{GetOptimalTree1}{$p,c$}
                \Comment{Frequenzen und Perlengrößen}
                \State $n \gets |p|$  \Comment{Anzahl verschiedener Codewörter}
                \State $C \gets \max(c)$ \Comment{Größte Perle}
                \State $r \gets |c|$  \Comment{Anzahl Perlen}

                \State // Am Anfang enthält der Stack nur den Wurzel-Baum
                \State $stack \gets [([0, d_1, d_2, \dots, d_C],\;0,\;[])]$ \Comment{(Signatur, Kosten, Anzahl an internen Knoten)}
                \State $best\_cost \gets +\infty$
                \State $best\_tree \gets \text{null}$
                \While{$stack \neq \emptyset$}
                    \State $(\sigma,\,cost,\,Qs) \gets stack.\mathrm{pop}()$
                    \If{$\sum \sigma > n\,(r-1)$}
                        \State \textbf{continue}
                    \EndIf
                    \If{$\sigma[0] \ge n$}
                        \If{$cost < best\_cost$}
                            \State $best\_cost \gets cost$
                            \State $best\_tree \gets Qs$
                        \EndIf
                        \State \textbf{continue}
                    \EndIf
                    \State $new\_cost \gets cost \;+\;\sum_{i=\sigma[0]+1}^{n} p_i$
                    \If{$new\_cost > best\_cost$}
                        \State \textbf{continue}
                    \EndIf


                    \For{$q = 0$ \textbf{to} $\sigma[1]$}
                        \State $\sigma'\!\gets \textsc{expand}(\sigma,\,q)$
                        \State $stack.\mathrm{append}\bigl(\sigma',\;new\_cost,\;Qs + [q]\bigr)$
                    \EndFor
                \EndWhile
                \State \Return $\textsc{generate\_tree}(best\_tree,\;\textit{color\_sizes})$
            \EndFunction
        \end{algorithmic}
    \end{algorithm}
    Als erstes werden die Variablen $n$, $C$ und $r$ in Abhängigkeit von den Frequenzen der Buchstaben und der Größen der Farben initialisiert.
    Am Anfang enthält der Stack nur den Wurzel-Baum, dessen Signatur die Ebene-0-Kosten 0 hat.
    Im Stack wird außerdem gespeichert, durch welche Erweiterungen (Werte von $q$) der jeweilige Baum erreicht wurde.
    Die \textit{best\_cost} und \textit{best\_tree} Variablen speichern die Kosten und die Werte der Erweiterungen des bisher besten Baums.
    Die \textit{While}-Schleife läuft, bis alle Bäume besucht oder für zu teuer befunden wurden.
    Für jedes Element in \textit{stack} wird zuerst überprüft, ob es bereits zu viele Blätter hat, um die Vervollständigung eines optimalen Baums zu sein.\\
    Falls das erste Element der Signatur (also $m$) bereits größer oder gleich $n$ ist, hat der Baum genug Blätter um alle $n$ Buchstaben zu codieren.
    Wenn der Baum \glqq billiger\grqq~als der beste Baum ist, der bisher gefunden wurde, werden die Werte von $q$ gespeichert, die verwendet wurden, um den Baum zu erreichen. \\
    Falls der Baum noch nicht groß genug ist, muss er erweitert werden.
    Das hat aber einen Preis, der nun berechnet und mit dem besten Preis verglichen wird. \\
    Anschließend wird der Baum für jeden Wert von $q$ erweitert und die Ergebnisse werden wieder an den Stack angehängt. \\
    Nach dem Abschluss \textit{While}-Schleife haben wir in \textit{best\_cost} die Anzahl der internen Knoten des besten Baums.
    Dieser wird dann mit der \textsc{generate\_tree} Funktion generiert und zurückgegeben.
    Die Codetabelle kann anschließend über die Pfade zu den $n$ höchsten Blättern generiert werden. \\
    Da wir in Lemma~\ref{lem:funktioniert} gezeigt haben, dass jeder vollständige Baum (und damit auch $Fill(T_{opt})$) durch mehrere \textit{Expand} Operationen erzeugt werden kann, findet Algorithmus~\ref{alg:optimal_tree} sicher den optimalen Baum. \\

    Ich verzichte hier auf eine Laufzeitbetrachtung, da im Folgenden ein effizienterer Algorithmus vorgestellt wird.

    \subsection{Reduktion auf $n$ Blätter}
    Im vorherigen Kapitel haben wir uns der Einfachheit halber auf vollständige Bäume beschränkt.
    Dadurch mussten wir aber immer Bäume mit bis zu $n(r - 1)$ Blättern betrachten, was vor allem für große $n$ und $r$ zu langer Rechenzeit führt.
    Da wir die optimalen Bäume trotzdem wie im vorherigen Kapitel Ebene für Ebene generieren wollen, definieren wir die \textit{Reduce}-Funktion um \glqq überschüssige\grqq~Blätter zu entfernen.
    \begin{definition}
        Wir reduzieren einen Baum $T$ zu $Reduce(T)$, indem wir nur die $n$ höchsten Blätter behalten und den Rest entfernen.
        Falls dabei interne Knoten zu Blättern werden, entfernen wir diese ebenfalls (und wiederholen diesen Prozess ggf.).
    \end{definition}
    \begin{korollar}
        Wir können wieder einige offensichtlichen Eigenschaften der \textit{Reduce}-Funktion sammeln:
        \begin{enumerate}
            \item Falls $T$ weniger als $n$ Blätter hat, gilt $Reduce(T) = T$
            \item $Reduce(T)$ ist einzigartig bis auf Äquivalenz
            \item Für jeden Ebene-$i$-Baum $T$ gilt $cost_i(Reduce(T) = cost_i(T))$
        \end{enumerate}
    \end{korollar}
    Um die Bäume wieder anhand der Signatur zu unterscheiden, müssen wir betrachten, wie sich die Signatur eines Baums $T$ mit $sig_i(T) = (m, l_1, \dots, l_C)$ durch eine Reduktion verändert.
    Man kann die neue Signatur $sig_i(Reduce(T) = (m', l_1', \dots, l_C'))$ folgendermaßen berechnen: \\
    \begin{algorithm} [H]
        \caption{\textsc{Reduce}}
        \label{alg:reduce}
        \begin{algorithmic}[1]
            \State $m' \gets \min\{m, n\}$
            \State $l_1' \gets \min\{l_j, n - m'\}$
            \ForAll{$j \in [2, \dots, C]$}
                \State $l_j' \gets \min\{l_j, n - (m' + \sum^{j-1}_{k=1}l_k')\}$
            \EndFor
        \end{algorithmic}
    \end{algorithm}

    \begin{lemma}
        Sei $T_{opt}$ ein optimaler Baum der Höhe $h$.
        Sei $T_i = Cut_i(T)$ und $q_i$ die Anzahl an internen Knoten von $T$ auf Ebene $i \in \{1, \dots, h\}$.
        Dann gilt: $T_i = Reduce(Expand_i(T_{i-1}, q_i))$.
        In anderen Worten: \\
        $T_{opt}$ kann bis auf Äquivalenz durch $h$-fache Iteration der Funktion $T' = Reduce(Expand(T',q))$ (für bestimmte Werte von $q$) erzeugt werden.
    \end{lemma}
    \begin{proof}

    \end{proof}
    Wir haben also gezeigt, dass wir den optimalen Baum durch mehrfaches Anwenden der \textit{Expand} und \textit{Reduce} Funktionen erzeugen können.
    Das können wir durch eine Modifikation des vorherigen Algorithmus erreichen:
    \begin{algorithm} [H]
        \caption{\textsc{GetOptimalTree}\,(Frequenzen, Farbengrößen)}
        \begin{algorithmic}[1]
            \Function{GetOptimalTree}{$p,c$}
                \Comment{Frequenzen und Perlengrößen}
                \State $n \gets |p|$  \Comment{Anzahl verschiedener Codewörter}
                \State $C \gets \max(c)$ \Comment{Größte Perle}
                \State $r \gets |c|$  \Comment{Anzahl Perlen}

                \State // Initialisiere Stack mit Tupel (Signatur, Kosten, Expansionsliste)
                \State $stack \gets [([0, d_1, d_2, \dots, d_C],\;0,\;[])]$
                \State $best\_cost \gets +\infty$
                \State $best\_tree \gets \text{null}$
                \While{$stack \neq \emptyset$}
                    \State $(\sigma,\,cost,\,Qs) \gets stack.\mathrm{pop}()$
                    \State $new\_cost \gets cost \;+\;\sum_{i=\sigma[0]}^{n-1} p[i]$
                    \If{$new\_cost > best\_cost$}
                        \State \textbf{continue}
                    \EndIf
                    \If{$\sigma[0] \ge n$}
                        \If{$cost < best\_cost$}
                            \State $best\_cost \gets cost$
                            \State $best\_tree \gets Qs$
                        \EndIf
                        \State \textbf{continue}
                    \EndIf

                    \For{$q = 0$ \textbf{to}  $\sigma[1]$}
                        \State $\sigma'\!\gets \textsc{reduce}(\textsc{expand}(\sigma,\,q))$
                        \State $stack.\mathrm{append}\bigl(\sigma',\;new\_cost,\;Qs + [q]\bigr)$
                    \EndFor
                \EndWhile
                \State \Return $\textsc{generate\_tree}(best\_tree,\;\textit{color\_sizes})$
            \EndFunction
        \end{algorithmic}\label{alg:algorithm}
    \end{algorithm}
    Da wir den Reduktionsschritt hinzugefügt haben, müssen wir hier nicht mehr überprüfen, ob die Signatur mehr als $n (r - 1)$ Blätter hat. \\
    In dem Paper\autocite{golin_dynamic_1998} wird eine einfache Optimierung vorgeschlagen, mit der nicht immer alle Werte von $q$ durchlaufen werden müssen.
    \begin{lemma}
        \label{lem:reader_1}
        Es ist ausreichend, dass $q$ nur die Werte $\left[0, \dots, \min\left\{l_1, n - \left(m + \sum^{c_2}_{j=1} l_j\right)\right\}\right]$ durchläuft.
    \end{lemma}
    Leider wurde diese Optimierung jedoch nicht bewiesen oder näher erläutert, es wurde lediglich gesagt: \glqq We leave it as an exercise for the reader to check that this is correct.\grqq \\
    Als vorbildlicher Leser habe ich mir natürlich die Mühe gemacht und mir den Kopf über diesen Beweis zerbrochen:
    \begin{proof}
        Der Beweis wird deutlich anschaulicher, wenn man zuerst den Fall $c_1 = c_2 = 1$ und $c_3 = 2$ betrachtet.
        Sei $sig_i = (m, l_1, l_2)$ also die Signatur eines Ebene-$i$-Baums $T$, den wir nun um $q$ erweitern wollen.
        Um zu zeigen, dass alle Erweiterungen mit $q > \min\{l_1, n - (m + \sum^{c_2}_{j=1} l_j)\}$ redundant sind, setzen wir $q \gets n - (m + l_1) + 1$. \\
        Sei $T' = Expand(T, q)$ mit der Signatur $sig_{i+1}(T') = (m', l_1', l_2')$.
        Durch die Regeln der Erweiterung wissen wir:
        \begin{enumerate}
            \item $m' = m + l_1 - q$
            \item $l_1' = l_2 + d_1 \cdot q = l_2 + 2 \cdot q$
            \item $l_2' = 0 + d_2 \cdot q = q$
        \end{enumerate}
        Für die Anzahl der Blätter auf den Ebenen $0, \dots, i + 1$ gilt jetzt:
        \begin{equation}
            \begin{aligned}
                m'+ l_1' &= m + l_1 - q + l_2 + 2 \cdot q\\
                &= m + l_1 + l_2 + q\\
                &= m + l_1 + l_2 + n - (m + l_1) + 1\\
                &= l_2 + n + 1
            \end{aligned}\label{eq:equation}
        \end{equation}
        Als nächsten Schritt kürzen wir den Baum mit der \textit{Reduce} Funktion.
        Da wir bereits auf den Ebenen $0$ bis $i+1$ mehr als $n$ Blätter haben, werden die Blätter auf den nachfolgenden Ebenen auf jeden Fall gekürzt.
        Aber auch in der Ebene $i + 1$ müssen $l_2 + 1$ Blätter gekürzt werden.
        Vor der Expansion waren auf der Ebene $i + 1$ genau $l_2$ Blätter, zu denen wir $q \cdot 2$ Blätter hinzugefügt haben. \\
        Um den Beweis weiterzuführen, müssen wir die Struktur der Ebene $i+1$ betrachten, vor allem die der neu hinzugefügten Blätter.
        Jedes der $q$ Blätter aus Ebene $i$, das durch unsere Expand-Operation zu einem internen Knoten gemacht wurde, hatte vor der Reduktion $2$ Kinder auf Ebene $i + 1$ und eines auf Ebene $i + 2$.
        Das Kind auf Ebene $i + 2$ wird durch die Reduktion auf jeden Fall entfernt.
        Da wir nun $l_2 + 1$ Blätter aus Ebene $i + 1$ kürzen müssen, wird mindestens ein Knoten, der vorher erweitert wurde, nur noch ein Kind haben. (Da die Ebene $i + 1$ vor der Erweiterung $l_2$ Blätter hatte und $l_2 + 1$ Blätter heraus gekürzt werden müssen.)
        Durch die Reduktion werden diese Knoten, die nur noch ein Kind haben, dann zu einem Blatt gemacht.
        Dadurch erreicht man einen Zustand, den man auch mit einer Erweiterung mit einem kleineren $q$ erreicht hätte.
        Dieser wurde aber schon in einer vorherigen Iteration der Schleife berücksichtigt.
        Wir haben also für das Beispiel $c_1 = c_2 = 1$ und $c_3 = 2$ gezeigt, dass es genügt, wenn $q$ die Werte $[0, \dots, \min\{l_1, n - (m + \sum^{c_2}_{j=1} l_j)\}]$ durchläuft.\\
        Die Verallgemeinerung dieses Beweises ist trivial und wird daher dem Leser überlassen.
        (Falls der Leser sich eine Lösung wünscht, ist diese im Anhang zu finden: Lemma \ref{lem:reader_2}.)
    \end{proof}

    \subsubsection{Laufzeit}
    Im Worst-Case werden alle Bäume (bis auf Äquivalenz) mit $\le n$ Blättern betrachtet.
    Ein solcher Baum hat maximal $I = n - 1$ interne Knoten (TODO ref lemma) und eine maximale Tiefe von $h = n - 1$.
    Sei $q_i$ die Anzahl der internen Knoten auf Ebene $i$ mit $1 \le i \le n - 2$.
    Wir müssen folgende strikt steigende Sequenz betrachten:
    \[(q_1, q_2 + 1, \dots, q_1 + q_2 + \dots + q_{n - 2} + n - 3)\]
    Diese Sequenz ist eine Teilmenge der $n$-er Teilmengen von $\{0, \dots, 2n - 4\} \subseteq \{0, \dots, 2n\}$.
    Wir können daher folgende Obergrenze für die Laufzeit des Algorithmus angeben:
    \[O\left({{2n} \choose n}  \right)\]

    Falls gilt $p_0 = p_1 = \dots = p_n$ können wir eine bessere Abschätzung machen.
    Da nun ein Baum gesucht ist, bei dem die Knoten alle auf einer ähnlichen Ebene liegen, kann die Tiefe durch $h = \log_r(n) \cdot C$
    begrenzt werden.
    Mit dieser Abschätzung kann die Berechnung wie oben durchgeführt werden und man erhält eine Obergrenze von:
    \[O\left({n + h} \choose h \right)\]

    \subsection{Diskussion der Laufzeit}
    Die oben angegebene Laufzeit ist aber nur eine Obergrenze, die für die theoretische Korrektheit mehrere Extremfälle beachten muss:
    Die maximale Anzahl der internen Knoten entsteht bei einem Baum, bei dem jeder Knoten nur zwei Kinder hat und die maximale Tiefe entsteht bei einem Baum, bei dem jeder Knoten genau zwei Kinder und jede ebene genau einen internen Knoten hat, was extrem unrealistisch ist.
    Des Weiteren sind viele der möglichen $n$-er Teilmengen von $\{0, \dots, 2n\}$ gar keine gültigen Bäume. \\
    In dem Paper\autocite{golin_dynamic_1998} wird ein Algorithmus mit der Laufzeit $O(C^{C+2})$ vorgestellt.
    Diese ist zwar asymptotisch deutlich besser als die Laufzeit von meinem Algorithmus, in diesem Algorithmus werden aber
    immer genau ${n + C + 1}\choose {C+ 1}$ Knoten besucht, deren Kosten alle in einem Array gespeichert werden müssen.
    Die Stärke von meinem Algorithmus ist, dass zuerst große Bäume berechnet werden (da mit \textit{it} immer der letzt Wert aus dem Stack entfernt wird) und dadurch schnell eine gute Obergrenze für die Kosten des optimalen Baums gefunden werden kann.
    Alle Bäume mit größeren Kosten können dann bereits vor der fertigstellung übersprungen werden.
    Um zu testen, ob mein Algorithmus trotz asymptotisch schlechterer Laufzeit tatsächlich weniger Knoten besucht, habe
    ich für die Beispieldateien berechnet, wie viele Bäume der Algorithmus aus dem Paper besucht hätte (und damit abspeichern müsste).
    Diesen Wert habe ich mit der Anzahl an besuchten Bäumen von meinem Algorithmus verglichen:
    \begin{figure}[H]
        \centering
        \begin{tabular}{c |c | c}
            Beispieldatei & Anzahl Paper   & Anzahl mein Algorithmus \\
            \hline
            0             & 455            & 159                     \\
            1             & 23751          & 901                     \\
            2             & 220            & 1096                    \\
            3             & 715            & 104                     \\
            4             & 680            & 2866                    \\
            5             & 450978066      & 1629                    \\
            6             & 73815          & 8454                    \\
            7             & 60962903966874 & 1376                    \\
            8             & 1621509963255  & 12321043                \\
        \end{tabular}
    \end{figure}
    Man sieht, dass mein Algorithmus in der Praxis vor allem für Beispieldateien mit großem $n$ deutlich schneller ist, als der theoretisch schnellere Algorithmus aus dem Paper.

    \subsection{Heuristik}
    Für große Eingabealphabete ($n \gg 500$) ist mein Algorithmus trotzdem deutlich zu langsam.
    Daher habe ich eine Heuristik entwickelt, mit der selbst große Codetabellen in kurzer Zeit approximiert werden können. \\
    Dafür müssen die Buchstaben zuerst anhand einer Cutoff-Wahrscheinlichkeit $P_{cut}$ (z.B. $P_{cut} = 0.05$) in häufige und seltene Buchstaben aufgeteilt werden.
    Alle Buchstaben mit $p_i \ge P_{cut}$ werden ab jetzt als \textit{häufige} Buchstaben $P_h$ bezeichnet, die restlichen Buchstaben mit $p_i < P_{cut}$ sind \textit{seltene} Buchstaben $P_s$:
    \[P_{h} = \{p_i \mid p_i \ge P_{cut}\}~~~~~P_s = \{p_i \mid p_i < P_{cut}\} \text{~~~für alle $p_i$}\]
    Für große $n \gg 500$ gibt es sehr viel mehr seltene Buchstaben, die aufgrund ihrer kleinen Wahrscheinlichkeit aber wenig zur gesamten Codelänge beitragen.
    Die Heuristik beruht auf der Annahme, dass die seltenen Wahrscheinlichkeiten $p_i < P_{cut}$ so geringe Unterschiede haben, dass sie als gleich angesehen werden können.
    Da es trotzdem noch deutlich zu viele seltenen Wahrscheinlichkeiten gibt, um einen passenden Baum mit der Funktion \ref{alg:algorithm} zu generieren, werden die seltenen Wahrscheinlichkeiten anhand einer größe $S$ in \glqq Chunks\grqq~aufgeteilt.
    Für einen der Chunks wird dann mit der \textit{GetOptimalTree} Funktion ein optimaler Baum $T_c$ generiert, mit der Eingabe: $(p_1, \dots, p_s) = \textit{Chunks}[0]$.
    \[T_c = \textit{GetOptimalTree}((p_1, \dots, p_s), (c_1, c_2, \dots c_r))\]
    Anschließend wird für die häufigen Buchstaben und die Summen der Chunks der Haupt-Baum $T$ mit $|P_h| + |Chunks|$ Blättern generiert:
    \[p_1, \dots, p_{|P_h|} = P_h~~~~~~p_{|P_h| + i} = \sum \textit{Chunks}[i]\]
    \[T = \textit{GetOptimalTree}((p_1, \dots, p_{|P_h| + |Chunks|}), (c_1, c_2, \dots c_r)\]
    Die höchsten $|P_h|$ Blätter von $T$ sind für die häufigen Buchstaben \glqq reserviert\grqq.
    An die restlichen $|Chunks|$ Blätter wird jeweils eine Kopie von $T_c$ angehängt. \\
    Wie \glqq optimal\grqq~der fertige Baum ist, hängt hauptsächlich von der Chunkgröße $S$ ab.
    Da der vorherige Algorithmus sehr schnell abläuft, kann auch ein Bereich an Chunkgrößen ausprobiert werden, um eine gute Approximation zu finden.

    \subsubsection{Laufzeit}
    Die \textit{GetOptimalTree} Funktion wird zweimal aufgerufen, einmal $n = S$ und einmal mit
    \[n = |P_h| + |Chunks| = |P_h| +  \left\lfloor   \frac {|P_s|} {S}  \right\rfloor + 1\]
    Da $|P_h| \le 20$ (für $P_{cut} = 0.05$), muss $|P_h|$ in der Laufzeitbetrachtung nicht beachtet werden.
    Da die \textit{GetOptimalTree} Funktion eine Laufzeit von $O\left({{2n} \choose n}  \right)$ hat und zweimal mit verschiedenen $n$ aufgerufen wird, ist die Laufzeit der Heuristik $O\left({{2x} \choose x}  \right)$ mit
    \[x = \max \left\{ S, \left\lfloor   \frac {|P_s|} {S}  \right\rfloor + 1 \right\} \le \max \left\{S, \left\lceil \frac n S \right\rceil \right\}.\]


    \section{Umsetzung}


    \section{Beispiele}

    \begin{figure}

    \end{figure}

    Genügend Beispiele einbinden! Die Beispiele von der BwInf-Webseite sollten hier diskutiert werden, aber auch eigene Beispiele sind sehr gut – besonders wenn sie Spezialfälle abdecken. Aber bitte nicht 30 Seiten Programmausgabe hier einfügen!

    TODO Latex datei der Dokumentation reinwerfen


    \section{Quellcode}
    Unwichtige Teile des Programms sollen hier nicht abgedruckt werden. Dieser Teil sollte nicht mehr als 2–3 Seiten umfassen, maximal 10.


    \section{Anhang}
    Tatsächlich:
    \begin{lemma}
        \label{lem:reader_2}
        Es ist ausreichend, dass $q$ nur die Werte $[0, \dots, \min\{l_1, n - (m + \sum^{c_2}_{j=1} l_j)\}]$ durchläuft.
    \end{lemma}
    \begin{proof}
        Sei $sig_i(T) = (m, l_1, \dots, l_C)$ wieder die Signatur des Ebene-$i$-Baums $T$, den wir nun um $q$ erweitern wollen.
        Wir setzen $q \gets n - (m + \sum^{c_2}_{j=1} l_j) + x$ mit $x \in \mathbb N$ und $x > 0$, um zu zeigen, dass alle Erweiterungen mit $q > \min\{l_1, n - (m + \sum^{c_2}_{j=1} l_j)\}$ redundant sind. \\
        Sei $T' = Expand(T, q)$ mit der Signatur $sig_i(T') = (m', l_1', \dots, l_C')$.
        Durch die Regeln der Erweiterung wissen wir:
        \begin{enumerate}
            \item $m' = m + l_1 - q$
            \item $l_j' = l_{j+1} + q \cdot d_j$
        \end{enumerate}
        Entweder ist $c_1 = c_2$ oder $c_1 < c_2$.
        Wir beschäftigen uns zuerst mit dem Fall, dass $c_1 < c_2$. \\

        Für die Anzahl aller Blätter auf den Ebenen $0, \dots, i + c_2$ gilt jetzt:
        \begin{equation}
            \begin{aligned}
                m' + \sum^{c_2}_{j=1} l_j' &= m + l_1 - q + \sum^{c_2}_{j=1} l_{j+1} + q \cdot d_j\\
                &= m + l_1 - q + \left(\sum^{c_2-1}_{j=1} l_{j+1} + q \cdot d_j\right) + l_{c_2 + 1} + q \cdot d_{c_2}\\
                &\text{Da $c_1 < c_2$ gilt $d_j = 0$ für alle $j \in \{j \in \mathbb N \mid j < c_2 \land j \neq c_1\}$. Es gilt aber $d_{c_1} = 1$.} \\
                &\text{$q \cdot d_j$ ist in der Summe also nur einmal relevant und kann daher \glqq herausgezogen\grqq~werden.} \\
                % TODO den schritt erklären (weil d_j nur einmal = 1) für j < c_2
                &= m + l_1 - q + l_{c_2 + 1} + q \cdot d_{c_2} + \left(\sum^{c_2-1}_{j=1} l_{j+1}\right) + q\\
                &= m + l_1 + l_{c_2 + 1} + q \cdot d_{c_2} + \sum^{c_2-1}_{j=1} l_{j+1}\\
                &=m + l_1 + l_{c_2 + 1} + q + q \cdot (d_{c_2} - 1)  + \sum^{c_2-1}_{j=1} l_{j+1} \\
                &= m + l_1 +  \left(n - (m + \sum^{c_2}_{j=1} l_j) + x\right) + q \cdot (d_{c_2} - 1) + \sum^{c_2-1}_{j=1} l_{j+1} \\
                &= m + l_{c_2 + 1} +  \left(n - (m + \sum^{c_2}_{j=1} l_j) + x\right) + q \cdot (d_{c_2} - 1) + \sum^{c_2}_{j=1} l_{j} \\
                &= n + l_{c_2 + 1} + q \cdot (d_{c_2} - 1) + x\\
            \end{aligned}\label{eq:equation2}
        \end{equation}
        Wir können jetzt wieder wie im oberen Beweis vorgehen und den Reduktionsvorgang nachvollziehen. \\
        Auf allen Ebenen $> i + c_2$ müssen auf jeden Fall alle Blätter gelöscht werden, da schon bis Ebene $i + c_2$ mehr als $n$ Blätter erreicht sind.
        Da $c_1 \le c_2$ hat jeder Knoten, den wir vorher erweitert haben, genau $d_2 + 1$ Kinder.
        Wir müssen auf jeden Fall wieder die $l_{c_2 + 1}$ Blätter löschen, die bereits vor der Erweiterung da waren.
        Anschließend müssen wir weitere $q \cdot (d_{c_2} - 1)$ Blätter entfernen.
        Jeder der Knoten, die wir vorher erweitert haben, hat nun genau ein Kind auf Ebene $i + c_1$ und ein Kind auf Ebene $i + c_2$.
        Wir müssen aber noch $x > 0$ Blätter auf Ebene $i + c_2$ löschen, d.h.\ es gibt wieder mindestens einen Knoten, der nur ein Kind hat.
        Durch weitere Reduktion entsteht nun ein Zustand, der auch durch eine Erweiterung mit einem kleineren $q$ erreicht werden könnte (siehe Beweis von Lemma \ref{lem:reader_1}). \\
        Der Fall $c_1 = c_2$ ist eine triviale Abwandlung dieses Beweises und wird dem Leser überlassen :)
    \end{proof}


    \section{Literatur}
    \printbibliography[heading=none]

\end{document}
